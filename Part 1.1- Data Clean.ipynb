{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from zipfile import ZipFile \n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates Headers, Links to holder and makes new folder to store cleaned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the first row of headers (I pulled them from down below and put them here then removed the print function)\n",
    "headers = [\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It saves the directory of the file called ZipFiles which is currently holding the uncleaned zip files \n",
    "#and names it as the variable zip_files\n",
    "#it also creates a temporary directory (Folder) for the cleaned files called temp_clean\n",
    "\n",
    "\n",
    "zip_files = os.listdir(\"ZipFiles\")\n",
    "\n",
    "if not os.path.isdir(\"temp_clean\") : # if folder exists\n",
    "    os.mkdir(\"temp_clean\")           # if not, make it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Cleaning and Creating New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read each folder in the zip_files (where the uncleaned folders are stored)\n",
    "\n",
    "for zip_file in zip_files :\n",
    "    with ZipFile(\"ZipFiles/\" + zip_file,'r') as my_zip_file : \n",
    "    \n",
    "        files_inside = my_zip_file.namelist()\n",
    "        for zipped_file in files_inside :\n",
    "            sniffer = csv.Sniffer() #checks if it has a header\n",
    "\n",
    "            #opens,unzips, and reads each file in the zipped folder and name this input_file, \n",
    "            #the output files names will be the same name but ends in .clean.csv\n",
    "            \n",
    "            with my_zip_file.open(zipped_file,'r') as input_file :\n",
    "            \n",
    "                \n",
    "                output_file_name = input_file.name.replace(\".csv\",\"_clean.csv\")\n",
    "    \n",
    "                #open the folder for the new files that was created above and create a new file using the out_file_name\n",
    "                with open(\"temp_clean/\" + output_file_name,'w') as outfile : \n",
    "                    outfile.write(\",\".join(headers) + \"\\n\") #adds header to the first line of the file since we remove it below\n",
    "               \n",
    "            \n",
    "                    #the following code removes the byte format, removes the quotes, \n",
    "                    #and replaces the null characters with blanks for each line in the input file                \n",
    "                    rows_printed = 0\n",
    "                    for idx, line in enumerate(input_file) :\n",
    "\n",
    "                        file_has_header = False\n",
    "\n",
    "                        dialect = sniffer.sniff(line.decode(\"utf-8\"))\n",
    "                        line = line.decode(\"utf-8\").strip().split(dialect.delimiter)\n",
    "                        line = [piece.replace('\"','') for piece in line]\n",
    "                        line = [piece.replace('NULL','') for piece in line]\n",
    "                        line = [piece.replace('\\\\N','') for piece in line]\n",
    "                        \n",
    "                        #there was an issue with three columns in the dataset that should be one column, \n",
    "                        #this finds the line that is too long, combines the three columns, removes the bad column, and inserts the correct column\n",
    "                        if len(line) != 50:\n",
    "                            bad_line = line\n",
    "                            bad_line[5:8] #the issue is in columns 5 through 7\n",
    "                            new_column = (\"\".join(bad_line[5:8]))\n",
    "                            #print(new_column)\n",
    "                            \n",
    "                            #delete bad\n",
    "                            #print(len(bad_line))\n",
    "                            del bad_line[5:8]\n",
    "                            #print(bad_line)\n",
    "                            #print(len(bad_line))\n",
    "                            \n",
    "                            #insert good\n",
    "                            bad_line.insert(5,new_column)\n",
    "                            #print(bad_line)\n",
    "                            #print(len(bad_line))                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        #if the first row has datetime in it, then the file has a header\n",
    "                        if idx == 0 :\n",
    "                            if 'datetime' in line[0] :\n",
    "                                file_has_header = True\n",
    "                        \n",
    "                        #if the first row has a header, then dont print the header but write the rest of the lines to the file\n",
    "                        if file_has_header and idx == 0 :\n",
    "                            # don't print line\n",
    "                            pass\n",
    "                        else : \n",
    "                            outfile.write(\",\".join(line) + \"\\n\")\n",
    "                            rows_printed += 1\n",
    "                               \n",
    "    \n",
    "                        \n",
    "#print(\"Finished processing all files into clean files\") #this way I know it finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
